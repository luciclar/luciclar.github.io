[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Research topics",
    "section": "",
    "text": "Estimation of spatio-temporal model by deep learning\n\n\n\ndeep learning\n\n\nspatial statistics\n\n\nsbi\n\n\n\nJoint work with Alexandre Loret (PhD student), Nicolas Desassis, Thomas Romary and Vincent Fourmigué (M2 student)\n\n\n\nLucia Clarotto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpatio-Temporal Prediction Using Stochastic Partial Differential Equations for Advection-Diffusion on Riemannian Surfaces\n\n\n\nspde\n\n\nspatial statistics\n\n\nRiemannian surfaces\n\n\nadvection-diffusion\n\n\n\nJoint work with Mike Pereira and Nicolas Desassis\n\n\n\nLucia Clarotto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics-Informed Neural Networks for SPDEs\n\n\n\npinns\n\n\nspde\n\n\ngenerative models\n\n\n\nWork with Hugo Gangloff, Nicolas Jouvin, Antoine Regardin (M2 student)\n\n\n\nLucia Clarotto\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPhysics-Informed Neural Networks for parameter estimation in SDEs\n\n\n\npinns\n\n\nsde\n\n\ngenerative models\n\n\nspatial ecology\n\n\n\nWork with Sophie Donnet, Hugo Gangloff, Nicolas Jouvin\n\n\n\nLucia Clarotto\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "An incomplete list of research topics I’m interested in:"
  },
  {
    "objectID": "research.html#list-of-publications",
    "href": "research.html#list-of-publications",
    "title": "Research",
    "section": "List of publications",
    "text": "List of publications\n\n\nAllard, Denis, Lucia Clarotto, and Xavier Emery. 2022. “Fully Nonseparable Gneiting Covariance Functions for Multivariate Space–Time Data.” Spatial Statistics 52: 100706. https://doi.org/10.1016/j.spasta.2022.100706.\n\n\nAllard, Denis, Lucia Clarotto, Thomas Opitz, and Thomas Romary. 2021. “Discussion on ‘Competition on Spatial Statistics for Large Datasets’.” Journal of Agricultural, Biological and Environmental Statistics 26. https://doi.org/10.1007/s13253-021-00462-2.\n\n\nClarotto, Lucia, Denis Allard, and Alessandra Menafoglio. 2022. “A New Class of α-Transformations for the Spatial Analysis of Compositional Data.” Spatial Statistics 47: 100570. https://doi.org/10.1016/j.spasta.2021.100570.\n\n\nClarotto, Lucia, Denis Allard, Thomas Romary, and Nicolas Desassis. 2024. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Spatial Statistics 62: 100847. https://doi.org/10.1016/j.spasta.2024.100847.\n\n\nPereira, Mike, Lucia Clarotto, and Nicolas Desassis. 2025. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Hal-04132148. https://hal.science/hal-04132148."
  },
  {
    "objectID": "posts/pinns_spde/index.html",
    "href": "posts/pinns_spde/index.html",
    "title": "Physics-Informed Neural Networks for SPDEs",
    "section": "",
    "text": "Spatio-temporal data are prevalent in many applications within modern ecology and climate science. Statistical modeling of such data presents a significant challenge, historically focusing on Gaussian random fields (GRFs) and kriging for prediction . In a seminal paper, Lindgren, Rue, and Lindström (2011) proposed an inference methodology based on the fact that certain GRFs can be expressed as solutions to stochastic partial differential equations (SPDEs). The most famous example is the spatial Matérn GRFs, which are solutions to the diffusion-type equation:\n\\[\\begin{equation}\n(\\kappa^2-\\Delta)^{\\alpha/2} u = \\mathcal{W},\n\\end{equation}\\]\nwhere \\(\\mathcal{W}\\) is a stochastic forcing term (e.g., white noise), and \\(\\theta = (\\kappa, \\alpha)\\) are the model parameters, related to the Matérn covariance function. This approach bridges the gap between physical and statistical modeling, leading to a wealth of research refining the Equation above to model a broader class of random fields, and developing statistical inference procedures to estimate the model parameters. Most of these methods rely on a mesh-based approach, using finite elements or volumes to discretize the equation over a finite set of basis functions. On the other hand, physics-informed neural networks (PINNs, Raissi, Perdikaris, and Karniadakis (2019)) have recently been introduced to solve partial differential equations \\(\\mathcal{N}[u] = 0\\), where \\(\\mathcal{N}\\) is an arbitrary differential operator. The goal is to find the best neural network \\(u_\\nu\\) representing the solution by minimizing its PDE residuals computed at randomly sampled collocation points. This mesh-free approach has proven useful in various contexts and can be extended to inverse problems where the objective is to learn the parameters \\(\\theta\\) of the differential operator from certain observations of the solution.\nThis work aims to generalize the PINN approach to solve SPDEs. To do so, several modifications to the deterministic framework are necessary and will need to be explored. First, the neural network must represent a stochastic process, which can be achieved through generative modeling where the network \\(u_\\nu(Z)\\) has an additional latent variable \\(Z\\sim \\mathbb{Q}\\) as input. The quantity of interest then becomes the distribution \\(\\mathbb{P}_\\nu\\) of the network’s SPDE residuals \\(\\mathcal{N}[u_\\nu](Z)\\). This can be interpreted as a generative model, where \\(\\mathbb{P}_\\nu := \\mathcal{N}[u_\\nu](\\cdot) \\# \\mathbb{Q}\\) is the pushforward of the base distribution of \\(Z\\) through the PINN.\nSecond, it is necessary to define an appropriate loss function that accounts for the stochastic nature of the objects involved. Since SPDEs prescribe equality in distribution, a natural choice is to consider a measure of similarity between the probability distributions \\(D(\\mathbb{P}_\\nu, \\mathcal{W})\\). Several options are possible, such as Kullback-Leibler divergence, \\(p\\)-Wasserstein distance as in Arjovsky et al. (2017), or maximum mean discrepancy associated with a certain reproducing kernel (Gretton et al. 2012), each leading to different learning strategies for the network parameters \\(\\nu\\).\nThe goal is to explore and implement the various methodologies discussed above.\n\n\nA first step in this direction has been made by the M2 student Antoine Regardin during a 6-month internship in 2025.\nHe focused on one dimensional SPDEs and integrated randomness into the PINN framework through a Polynomial Chaos Expansion for the solution of the SPDE and a Karhunen-Loève expansion for the stochastic forcing random field.\nHe prepared the ground for generative models based on probability distribution metrics and weak form of the problems.\n\n\n\nGretton, Arthur, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. 2012. “A Kernel Two-Sample Test.” The Journal of Machine Learning Research 13 (1): 723–73.\n\n\nLindgren, Finn, Håvard Rue, and Johan Lindström. 2011. “An Explicit Link Between Gaussian Fields and Gaussian Markov Random Fields: The Stochastic Partial Differential Equation Approach.” Journal of the Royal Statistical Society Series B: Statistical Methodology 73 (4): 423–98.\n\n\nRaissi, Maziar, Paris Perdikaris, and George E Karniadakis. 2019. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707."
  },
  {
    "objectID": "posts/pinns_spde/index.html#physics-informed-neural-networks-for-spdes",
    "href": "posts/pinns_spde/index.html#physics-informed-neural-networks-for-spdes",
    "title": "Physics-Informed Neural Networks for SPDEs",
    "section": "",
    "text": "Spatio-temporal data are prevalent in many applications within modern ecology and climate science. Statistical modeling of such data presents a significant challenge, historically focusing on Gaussian random fields (GRFs) and kriging for prediction . In a seminal paper, Lindgren, Rue, and Lindström (2011) proposed an inference methodology based on the fact that certain GRFs can be expressed as solutions to stochastic partial differential equations (SPDEs). The most famous example is the spatial Matérn GRFs, which are solutions to the diffusion-type equation:\n\\[\\begin{equation}\n(\\kappa^2-\\Delta)^{\\alpha/2} u = \\mathcal{W},\n\\end{equation}\\]\nwhere \\(\\mathcal{W}\\) is a stochastic forcing term (e.g., white noise), and \\(\\theta = (\\kappa, \\alpha)\\) are the model parameters, related to the Matérn covariance function. This approach bridges the gap between physical and statistical modeling, leading to a wealth of research refining the Equation above to model a broader class of random fields, and developing statistical inference procedures to estimate the model parameters. Most of these methods rely on a mesh-based approach, using finite elements or volumes to discretize the equation over a finite set of basis functions. On the other hand, physics-informed neural networks (PINNs, Raissi, Perdikaris, and Karniadakis (2019)) have recently been introduced to solve partial differential equations \\(\\mathcal{N}[u] = 0\\), where \\(\\mathcal{N}\\) is an arbitrary differential operator. The goal is to find the best neural network \\(u_\\nu\\) representing the solution by minimizing its PDE residuals computed at randomly sampled collocation points. This mesh-free approach has proven useful in various contexts and can be extended to inverse problems where the objective is to learn the parameters \\(\\theta\\) of the differential operator from certain observations of the solution.\nThis work aims to generalize the PINN approach to solve SPDEs. To do so, several modifications to the deterministic framework are necessary and will need to be explored. First, the neural network must represent a stochastic process, which can be achieved through generative modeling where the network \\(u_\\nu(Z)\\) has an additional latent variable \\(Z\\sim \\mathbb{Q}\\) as input. The quantity of interest then becomes the distribution \\(\\mathbb{P}_\\nu\\) of the network’s SPDE residuals \\(\\mathcal{N}[u_\\nu](Z)\\). This can be interpreted as a generative model, where \\(\\mathbb{P}_\\nu := \\mathcal{N}[u_\\nu](\\cdot) \\# \\mathbb{Q}\\) is the pushforward of the base distribution of \\(Z\\) through the PINN.\nSecond, it is necessary to define an appropriate loss function that accounts for the stochastic nature of the objects involved. Since SPDEs prescribe equality in distribution, a natural choice is to consider a measure of similarity between the probability distributions \\(D(\\mathbb{P}_\\nu, \\mathcal{W})\\). Several options are possible, such as Kullback-Leibler divergence, \\(p\\)-Wasserstein distance as in Arjovsky et al. (2017), or maximum mean discrepancy associated with a certain reproducing kernel (Gretton et al. 2012), each leading to different learning strategies for the network parameters \\(\\nu\\).\nThe goal is to explore and implement the various methodologies discussed above.\n\n\nA first step in this direction has been made by the M2 student Antoine Regardin during a 6-month internship in 2025.\nHe focused on one dimensional SPDEs and integrated randomness into the PINN framework through a Polynomial Chaos Expansion for the solution of the SPDE and a Karhunen-Loève expansion for the stochastic forcing random field.\nHe prepared the ground for generative models based on probability distribution metrics and weak form of the problems.\n\n\n\nGretton, Arthur, Karsten M Borgwardt, Malte J Rasch, Bernhard Schölkopf, and Alexander Smola. 2012. “A Kernel Two-Sample Test.” The Journal of Machine Learning Research 13 (1): 723–73.\n\n\nLindgren, Finn, Håvard Rue, and Johan Lindström. 2011. “An Explicit Link Between Gaussian Fields and Gaussian Markov Random Fields: The Stochastic Partial Differential Equation Approach.” Journal of the Royal Statistical Society Series B: Statistical Methodology 73 (4): 423–98.\n\n\nRaissi, Maziar, Paris Perdikaris, and George E Karniadakis. 2019. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707."
  },
  {
    "objectID": "posts/deep_inference/index.html",
    "href": "posts/deep_inference/index.html",
    "title": "Estimation of spatio-temporal model by deep learning",
    "section": "",
    "text": "In geostatistics, Gaussian processes are commonly used to model spatial and spatio-temporal data because they allow for straightforward prediction of the variable of interest at unmeasured sites while quantifying the uncertainty of the prediction. In this context, the data are considered to be a realization of a Gaussian random field, whose covariance function needs to be estimated from the data. A classical approach for inference is to select a parameterized family of covariance functions and then choose the parameters that maximize the likelihood associated with the data. In practice, this approach often becomes a bottleneck, as even evaluating the likelihood function can quickly become computationally expensive when dealing with large amounts of data, especially in spatio-temporal settings. Therefore, it is desirable to have methods that allow for deducing the parameters of a covariance model without relying on the likelihood function.\nRecently, several methods using neural networks (notably CNNs and GNNs) have been proposed to address this issue. The main approach aims to train a neural network capable of identifying the parameters of a covariance function based on a realization of a Gaussian random field with that covariance (Gerber and Nychka 2021; Lenzi et al. 2023; Sainsbury-Dale et al. 2023). It can be considered a Simulation-Based Inference (SBI) approach, also called amortized inference.\n\n\nA first step in this direction has been made by the M1 student Antoine Regardin during a 3-month internship in 2024, funded by the Geolearning chair.\nThis internship aimed to develop and validate the GNN architecture proposed in Sainsbury-Dale et al. (2023), adapted to the spatial context. The architecture was coded in PyTorch with the library PyG(PyTorch_Geometric).\n\n\n\nAlexandre Loret has begun his PhD in october 2025 and he will address the generalization of the SBI approach to a setting adapted to spatio-temporal data. The main challenges of this generalization include designing a GNN architecture that accounts for spatio-temporal neighborhood structures and handling the estimation of a significantly larger number of parameters. He will also apply the approach to models derived from stochastic partial differential equations (Clarotto et al. 2024).\nMore generally, he will tackle the computational challenges of the inference of complex spatio-temporal models, exploring different approaches. Several possibilities exist to address this problem, among which hybrid models that integrate neural networks within Gaussian processes, such as Deep Gaussian Markov Fields, as well as variational inference methods or Neural Operators.\n\n\n\nClarotto, Lucia, Denis Allard, Thomas Romary, and Nicolas Desassis. 2024. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Spatial Statistics 62: 100847. https://doi.org/https://doi.org/10.1016/j.spasta.2024.100847.\n\n\nGerber, Florian, and Douglas Nychka. 2021. “Fast Covariance Parameter Estimation of Spatial Gaussian Process Models Using Neural Networks.” Stat 10 (1): e382. https://doi.org/https://doi.org/10.1002/sta4.382.\n\n\nLenzi, Amanda, Julie Bessac, Johann Rudi, and Michael L Stein. 2023. “Neural Networks for Parameter Estimation in Intractable Models.” Computational Statistics & Data Analysis 185: 107762.\n\n\nSainsbury-Dale, Matthew, Jordan Richards, Andrew Zammit-Mangion, and Raphaël Huser. 2023. “Neural Bayes Estimators for Irregular Spatial Data Using Graph Neural Networks.” arXiv Preprint arXiv:2310.02600."
  },
  {
    "objectID": "posts/deep_inference/index.html#estimation-of-spatio-temporal-model-by-deep-learning",
    "href": "posts/deep_inference/index.html#estimation-of-spatio-temporal-model-by-deep-learning",
    "title": "Estimation of spatio-temporal model by deep learning",
    "section": "",
    "text": "In geostatistics, Gaussian processes are commonly used to model spatial and spatio-temporal data because they allow for straightforward prediction of the variable of interest at unmeasured sites while quantifying the uncertainty of the prediction. In this context, the data are considered to be a realization of a Gaussian random field, whose covariance function needs to be estimated from the data. A classical approach for inference is to select a parameterized family of covariance functions and then choose the parameters that maximize the likelihood associated with the data. In practice, this approach often becomes a bottleneck, as even evaluating the likelihood function can quickly become computationally expensive when dealing with large amounts of data, especially in spatio-temporal settings. Therefore, it is desirable to have methods that allow for deducing the parameters of a covariance model without relying on the likelihood function.\nRecently, several methods using neural networks (notably CNNs and GNNs) have been proposed to address this issue. The main approach aims to train a neural network capable of identifying the parameters of a covariance function based on a realization of a Gaussian random field with that covariance (Gerber and Nychka 2021; Lenzi et al. 2023; Sainsbury-Dale et al. 2023). It can be considered a Simulation-Based Inference (SBI) approach, also called amortized inference.\n\n\nA first step in this direction has been made by the M1 student Antoine Regardin during a 3-month internship in 2024, funded by the Geolearning chair.\nThis internship aimed to develop and validate the GNN architecture proposed in Sainsbury-Dale et al. (2023), adapted to the spatial context. The architecture was coded in PyTorch with the library PyG(PyTorch_Geometric).\n\n\n\nAlexandre Loret has begun his PhD in october 2025 and he will address the generalization of the SBI approach to a setting adapted to spatio-temporal data. The main challenges of this generalization include designing a GNN architecture that accounts for spatio-temporal neighborhood structures and handling the estimation of a significantly larger number of parameters. He will also apply the approach to models derived from stochastic partial differential equations (Clarotto et al. 2024).\nMore generally, he will tackle the computational challenges of the inference of complex spatio-temporal models, exploring different approaches. Several possibilities exist to address this problem, among which hybrid models that integrate neural networks within Gaussian processes, such as Deep Gaussian Markov Fields, as well as variational inference methods or Neural Operators.\n\n\n\nClarotto, Lucia, Denis Allard, Thomas Romary, and Nicolas Desassis. 2024. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Spatial Statistics 62: 100847. https://doi.org/https://doi.org/10.1016/j.spasta.2024.100847.\n\n\nGerber, Florian, and Douglas Nychka. 2021. “Fast Covariance Parameter Estimation of Spatial Gaussian Process Models Using Neural Networks.” Stat 10 (1): e382. https://doi.org/https://doi.org/10.1002/sta4.382.\n\n\nLenzi, Amanda, Julie Bessac, Johann Rudi, and Michael L Stein. 2023. “Neural Networks for Parameter Estimation in Intractable Models.” Computational Statistics & Data Analysis 185: 107762.\n\n\nSainsbury-Dale, Matthew, Jordan Richards, Andrew Zammit-Mangion, and Raphaël Huser. 2023. “Neural Bayes Estimators for Irregular Spatial Data Using Graph Neural Networks.” arXiv Preprint arXiv:2310.02600."
  },
  {
    "objectID": "talks/talks.html",
    "href": "talks/talks.html",
    "title": "Talks",
    "section": "",
    "text": "Here are the various conference talks, workshops, lectures and presentations I’ve given.\n\n\n\n\n\nModeling CO2 concentration in the atmosphere using spatio-temporal random fields on meshed surfaces defined from advection-diffusion SPDEs\n\n\n\n\n\nInternational Meeting on Statistical Climatology (IMSC)\n\n\n\n\n\n2024-06-24\n\n\n2024-06-28\n\n\nToulouse, France\n\n\n\n\n\n\n\nParameter and density estimation in SDEs via PINNs and Normalizing Flows: applications to environmental sciences\n\n\n\n\n\nGeolearning Seminar\n\n\n\n\n\n2025-03-31\n\n\n2025-04-03\n\n\nFréjus, France\n\n\n\n\n\n\n\nSpatio-temporal random fields on meshed surfaces defined from advection-diffusion SPDEs: application to environmental data\n\n\n\n\n\nSéminaire de Probabilités et Statistique IMAG\n\n\n\n\n\n2025-04-07\n\n\n2025-04-07\n\n\nMontpellier, France\n\n\n\n\n\n\n\nScalable methods for simulation, inference and prediction of spatio-temporal random fields on meshed surfaces defined from advection-diffusion SPDEs\n\n\n\n\n\nSpatial Statistics 2025: At the Dawn of AI\n\n\n\n\n\n2025-07-15\n\n\n2025-07-18\n\n\nNoordwijk, The Netherlands\n\n\n\n\n\n\n\nScalable methods for simulation, inference and prediction of spatio-temporal random fields on meshed surfaces defined from advection-diffusion SPDEs\n\n\n\n\n\nGRASPA (Environmental Statistics) 2025\n\n\n\n\n\n2025-09-15\n\n\n2025-09-17\n\n\nRome, Italy\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/spde/index.html",
    "href": "posts/spde/index.html",
    "title": "Spatio-Temporal Prediction Using Stochastic Partial Differential Equations for Advection-Diffusion on Riemannian Surfaces",
    "section": "",
    "text": "Statisticians analyzing environmental data have recently shown great interest in introducing models inspired by the physics of underlying phenomena to improve prediction methods in a spatio-temporal context. The statistical method based on Stochastic Partial Differential Equations (SPDE) is an innovative approach to simulate, estimate, and predict spatial and spatio-temporal fields. A comprehensive and detailed formalism of the SPDE approach in the spatial context was introduced by Lindgren et al. (2011). Significant mathematical and algorithmic advances have been made over the past decade, enabling efficient handling of very large datasets Pereira et al. (2019). Moreover, Vergara et al. (2022) extended the approach to the spatio-temporal framework by incorporating physical processes related to the phenomena under study.\nThe SPDE approach relies on approximating a continuously indexed Gaussian random field (GRF) as a discretely indexed random process, specifically a Gaussian Markov random field (GMRF). Transitioning from a GRF to a GMRF replaces the dense covariance function and matrix with a neighborhood structure and a sparse precision matrix, respectively. The use of GMRFs with sparse precision matrices leads to computationally efficient numerical methods.\nTo better describe phenomena characterized by diffusive behavior that also exhibits transport in a preferred direction, I proposed in my thesis, completed in 2023, the class of advection-diffusion SPDEs:\n\\[\n\\left[\\frac{\\partial}{\\partial t} + \\frac{1}{c}(\\kappa^2 - \\nabla \\cdot \\mathbf{H}\\nabla)^{\\alpha} + \\frac{1}{c}\\mathbf{\\gamma} \\cdot \\nabla \\right] u = \\frac{\\tau}{\\sqrt{c}} \\mathcal{Z},\n\\]\nwhere \\(\\nabla \\cdot \\mathbf{H}\\nabla\\) is a diffusion operator with possible anisotropy \\(\\mathbf{H}\\), \\(\\mathbf{\\gamma} \\cdot \\nabla\\) is an advection operator, \\(\\alpha\\geq0\\) governs the regularity of \\(u\\), \\(\\kappa^2&gt;0\\) is a damping term related to the spatial range of \\(u\\), and \\(c\\) is a time scale parameter. Finally, \\(\\tau\\geq 0\\) is a standard deviation. The stochastic nature arises from the stochastic forcing term \\(\\mathcal{Z}\\), which can be a spatio-temporal white noise \\[\\mathcal{Z} = \\mathcal{W}_S \\otimes \\mathcal{W}_T\\] or a colored noise.\nThe different terms of the SPDE (advection, diffusion) directly influence the spatio-temporal dependencies of the process by controlling its variability in space and time.\nThrough finite element and finite difference discretization of the SPDE, this approach leads to a sparse structure in the precision matrix of the spatio-temporal field, allowing the use of fast algorithms for estimating SPDE parameters and for spatio-temporal prediction using kriging.\nCompared to spatio-temporal models built using covariance kernels, this model gains not only in computational efficiency but also in interpretability, as the model parameters can be linked to the physical coefficients of the SPDE.\nThe objective of this new work, in collaboration with Mike Pereira and Nicolas Desassis, is to propose a statistical model for spatio-temporal data on meshed surfaces based on the SPDE modeling approach. Specifically, we focus on a class of advection-diffusion SPDEs defined on smooth compact orientable closed Riemannian manifolds of dimension 2, and their discretization via a Galerkin approach. We demonstrate how this method enables the development of scalable algorithms for the simulation and prediction of Gaussian random fields that are solutions to the discretized SPDE. Additionally, we present recent developments in the inference of such models. The method is applied to a simulated spatio-temporal dataset exhibiting advective and diffusive behavior on the sphere, as well as to a real case study on aerosol optical depth in the atmosphere across the globe’s surface.\nMore details can be found in Clarotto et al. (2024) and Pereira, Clarotto, and Desassis (2025).\n\n\n\nClarotto, Lucia, Denis Allard, Thomas Romary, and Nicolas Desassis. 2024. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Spatial Statistics 62: 100847.\n\n\nPereira, Mike, Lucia Clarotto, and Nicolas Desassis. 2025. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Hal-04132148. https://hal.science/hal-04132148."
  },
  {
    "objectID": "posts/spde/index.html#spatio-temporal-prediction-using-stochastic-partial-differential-equations-for-advection-diffusion-on-riemannian-surfaces",
    "href": "posts/spde/index.html#spatio-temporal-prediction-using-stochastic-partial-differential-equations-for-advection-diffusion-on-riemannian-surfaces",
    "title": "Spatio-Temporal Prediction Using Stochastic Partial Differential Equations for Advection-Diffusion on Riemannian Surfaces",
    "section": "",
    "text": "Statisticians analyzing environmental data have recently shown great interest in introducing models inspired by the physics of underlying phenomena to improve prediction methods in a spatio-temporal context. The statistical method based on Stochastic Partial Differential Equations (SPDE) is an innovative approach to simulate, estimate, and predict spatial and spatio-temporal fields. A comprehensive and detailed formalism of the SPDE approach in the spatial context was introduced by Lindgren et al. (2011). Significant mathematical and algorithmic advances have been made over the past decade, enabling efficient handling of very large datasets Pereira et al. (2019). Moreover, Vergara et al. (2022) extended the approach to the spatio-temporal framework by incorporating physical processes related to the phenomena under study.\nThe SPDE approach relies on approximating a continuously indexed Gaussian random field (GRF) as a discretely indexed random process, specifically a Gaussian Markov random field (GMRF). Transitioning from a GRF to a GMRF replaces the dense covariance function and matrix with a neighborhood structure and a sparse precision matrix, respectively. The use of GMRFs with sparse precision matrices leads to computationally efficient numerical methods.\nTo better describe phenomena characterized by diffusive behavior that also exhibits transport in a preferred direction, I proposed in my thesis, completed in 2023, the class of advection-diffusion SPDEs:\n\\[\n\\left[\\frac{\\partial}{\\partial t} + \\frac{1}{c}(\\kappa^2 - \\nabla \\cdot \\mathbf{H}\\nabla)^{\\alpha} + \\frac{1}{c}\\mathbf{\\gamma} \\cdot \\nabla \\right] u = \\frac{\\tau}{\\sqrt{c}} \\mathcal{Z},\n\\]\nwhere \\(\\nabla \\cdot \\mathbf{H}\\nabla\\) is a diffusion operator with possible anisotropy \\(\\mathbf{H}\\), \\(\\mathbf{\\gamma} \\cdot \\nabla\\) is an advection operator, \\(\\alpha\\geq0\\) governs the regularity of \\(u\\), \\(\\kappa^2&gt;0\\) is a damping term related to the spatial range of \\(u\\), and \\(c\\) is a time scale parameter. Finally, \\(\\tau\\geq 0\\) is a standard deviation. The stochastic nature arises from the stochastic forcing term \\(\\mathcal{Z}\\), which can be a spatio-temporal white noise \\[\\mathcal{Z} = \\mathcal{W}_S \\otimes \\mathcal{W}_T\\] or a colored noise.\nThe different terms of the SPDE (advection, diffusion) directly influence the spatio-temporal dependencies of the process by controlling its variability in space and time.\nThrough finite element and finite difference discretization of the SPDE, this approach leads to a sparse structure in the precision matrix of the spatio-temporal field, allowing the use of fast algorithms for estimating SPDE parameters and for spatio-temporal prediction using kriging.\nCompared to spatio-temporal models built using covariance kernels, this model gains not only in computational efficiency but also in interpretability, as the model parameters can be linked to the physical coefficients of the SPDE.\nThe objective of this past year’s work, in collaboration with Mike Pereira and Nicolas Desassis, was to propose a statistical model for spatio-temporal data on meshed surfaces based on the SPDE modeling approach (Lindgren et al., 2011). To do this, we considered the class of advection-diffusion PDEs developed during my thesis (Clarotto et al., 2024), defined on compact, orientable, smooth, closed Riemannian manifolds of dimension 2, and their discretization using a Galerkin approach (Pereira et al., 2022).\nWe have demonstrated how this approach easily allows the proposal of scalable algorithms for the simulation, inference, and prediction of Gaussian random fields that are solutions to the discretized SPDE.\nMoreover, by varying the coefficients of the differential operators in the SPDE, it is possible to define a variety of non-stationary spatio-temporal models. This opens up the possibility of relaxing the stationarity assumption, which is often too restrictive in the study of environmental phenomena.\nWe applied the method to a simulated spatio-temporal dataset exhibiting advective and diffusive behavior on the sphere.\nWe are now working on a case study concerning particulate matter concentration in the atmosphere. The movement of particulate matter is essentially driven by advection processes (wind currents) and diffusion. Our statistical approach based on physical equations aims to account for this phenomenon.\nThe generality of the model and its adaptability to large datasets favor its application to a wide range of environmental and geoscientific data (wind, particulate matter concentration, water resources, etc.).\nMore details can be found in Clarotto et al. (2024) and Pereira et al. (2023)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Lucia Clarotto’s personal website"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lucia Clarotto",
    "section": "",
    "text": "Assistant Professor (Maîtresse de Conférences) in Statistics at AgroParisTech since september 2023.\nMMIP dept (Modélisation Mathématique, Informatique et Physique), UFR de Mathématique\nResearch at UMR MIA Paris-Saclay (Mathématique et Informatique Appliquées).\nFormerly PhD at Centre of Geosciences and Geoengineering, Mines Paris (2020-2023).\n\n\nOffice: E4.510 [=Building E, 4th floor, corridor 500, office 10]\nCampus Agro Paris-Saclay 22 place de l’Agronomie\n91120 PALAISEAU\n\n\n\n\n\n\n\nNews\n\n\n\nI welcome in my team Alexandre Loret, a PhD student under the supervision of Thomas Romary and Nicolas Desassis (Mines Paris) and myself. His PhD is funded by the Geolearning chair.\nHe will tackle the computational challenges of the inference of complex spatio-temporal models, exploring different techniques in Deep Leanrning.\nLet this new adventure begin!\n\n\n\n\n\n\n\n\nOpen positions\n\n\n\nTwo offers for a 6-month M2 internship or research project under my supervision (spring-summer 2026) are open in MIA Paris-Saclay.\n\nInference of spatio-temporal stochastic recurrence models for extreme oceanographic data\n\nwith Gloria Buritica\n\nPhysics Informed Neural Networks for parameter estimation in Stochastic Differential Equations\n\nwith Hugo Gangloff, Nicolas Jouvin and Sophie Donnet\nCheck those out!\n\n\n\nResearch\nAn incomplete list of research topics I’m interested in:\n\nSpatio-temporal statistics\nStochastic Partial Differential Equations\nDeep generative models\nPhysics-Informed Neural Networks (PINNs)\n\n\n\nTeaching\nI teach statistics (Linear and non-linear models, Machine Learning, Spatial Statistics, Bayesian Statistics…) at undergraduate and graduate students at AgroParisTech, Master BEE of University Paris Saclay, Mines Paris and Master EcoTrop of AgroParisTech and University of Guyana.\n\n\nShort description\n\nHere is my CV \nIn short, I am…\nIn more detail, I am…"
  },
  {
    "objectID": "posts/spde/index.html#prediction-of-spatio-temporal-data-on-meshed-surfaces-using-advection-diffusion-spdes",
    "href": "posts/spde/index.html#prediction-of-spatio-temporal-data-on-meshed-surfaces-using-advection-diffusion-spdes",
    "title": "Spatio-Temporal Prediction Using Stochastic Partial Differential Equations for Advection-Diffusion on Riemannian Surfaces",
    "section": "",
    "text": "Statisticians analyzing environmental data have recently shown great interest in introducing models inspired by the physics of underlying phenomena to improve prediction methods in a spatio-temporal context. The statistical method based on Stochastic Partial Differential Equations (SPDE) is an innovative approach to simulate, estimate, and predict spatial and spatio-temporal fields. A comprehensive and detailed formalism of the SPDE approach in the spatial context was introduced by Lindgren et al. (2011). Significant mathematical and algorithmic advances have been made over the past decade, enabling efficient handling of very large datasets Pereira et al. (2019). Moreover, Vergara et al. (2022) extended the approach to the spatio-temporal framework by incorporating physical processes related to the phenomena under study.\nThe SPDE approach relies on approximating a continuously indexed Gaussian random field (GRF) as a discretely indexed random process, specifically a Gaussian Markov random field (GMRF). Transitioning from a GRF to a GMRF replaces the dense covariance function and matrix with a neighborhood structure and a sparse precision matrix, respectively. The use of GMRFs with sparse precision matrices leads to computationally efficient numerical methods.\nTo better describe phenomena characterized by diffusive behavior that also exhibits transport in a preferred direction, I proposed in my thesis, completed in 2023, the class of advection-diffusion SPDEs:\n\\[\n\\left[\\frac{\\partial}{\\partial t} + \\frac{1}{c}(\\kappa^2 - \\nabla \\cdot \\mathbf{H}\\nabla)^{\\alpha} + \\frac{1}{c}\\mathbf{\\gamma} \\cdot \\nabla \\right] u = \\frac{\\tau}{\\sqrt{c}} \\mathcal{Z},\n\\]\nwhere \\(\\nabla \\cdot \\mathbf{H}\\nabla\\) is a diffusion operator with possible anisotropy \\(\\mathbf{H}\\), \\(\\mathbf{\\gamma} \\cdot \\nabla\\) is an advection operator, \\(\\alpha\\geq0\\) governs the regularity of \\(u\\), \\(\\kappa^2&gt;0\\) is a damping term related to the spatial range of \\(u\\), and \\(c\\) is a time scale parameter. Finally, \\(\\tau\\geq 0\\) is a standard deviation. The stochastic nature arises from the stochastic forcing term \\(\\mathcal{Z}\\), which can be a spatio-temporal white noise \\[\\mathcal{Z} = \\mathcal{W}_S \\otimes \\mathcal{W}_T\\] or a colored noise.\nThe different terms of the SPDE (advection, diffusion) directly influence the spatio-temporal dependencies of the process by controlling its variability in space and time.\nThrough finite element and finite difference discretization of the SPDE, this approach leads to a sparse structure in the precision matrix of the spatio-temporal field, allowing the use of fast algorithms for estimating SPDE parameters and for spatio-temporal prediction using kriging.\nCompared to spatio-temporal models built using covariance kernels, this model gains not only in computational efficiency but also in interpretability, as the model parameters can be linked to the physical coefficients of the SPDE.\nThe objective of this new work, in collaboration with Mike Pereira and Nicolas Desassis, is to propose a statistical model for spatio-temporal data on meshed surfaces based on the SPDE modeling approach. Specifically, we focus on a class of advection-diffusion SPDEs defined on smooth compact orientable closed Riemannian manifolds of dimension 2, and their discretization via a Galerkin approach. We demonstrate how this method enables the development of scalable algorithms for the simulation and prediction of Gaussian random fields that are solutions to the discretized SPDE. Additionally, we present recent developments in the inference of such models. The method is applied to a simulated spatio-temporal dataset exhibiting advective and diffusive behavior on the sphere, as well as to a real case study on aerosol optical depth in the atmosphere across the globe’s surface.\nMore details can be found in Clarotto et al. (2024) and Pereira, Clarotto, and Desassis (2025).\n\n\n\nClarotto, Lucia, Denis Allard, Thomas Romary, and Nicolas Desassis. 2024. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Spatial Statistics 62: 100847.\n\n\nPereira, Mike, Lucia Clarotto, and Nicolas Desassis. 2025. “The SPDE Approach for Spatio-Temporal Datasets with Advection and Diffusion.” Hal-04132148. https://hal.science/hal-04132148."
  },
  {
    "objectID": "posts/pinns_sde/index.html",
    "href": "posts/pinns_sde/index.html",
    "title": "Physics-Informed Neural Networks for parameter estimation in SDEs",
    "section": "",
    "text": "Stochastic Differential Equations (SDEs) are popular models in many fields including spatial ecology (Michelot et al. 2019), climate science (Ditlevsen and Ditlevsen 2023) and biology (Degond, Herda, and Mirrahimi 2020). Diffusion SDEs with additive noise are commonly found and defined as in Øksendal (2003): \\[\\mathrm{d}X_t=F(X_t;\\beta)\\, \\mathrm{d}t+\\Sigma\\, \\mathrm{d}W_t, \\quad X_0\\sim p_0\\] where \\((X_t)_t \\in\\mathbb{R}^d\\) is the stochastic process of interest, \\(W_t\\) is a \\(d\\)-dimensional Brownian noise, \\(p_0\\) is the initial distribution, \\(\\beta\\) parametrizes the drift of the equation and \\(\\Sigma\\) is the diffusion coefficient.\nWhen proposing such a model for observed trajectories at discrete times \\((x_{t_1}, \\dots, x_{t_n})\\), the next step consists in estimating the parameter \\(\\theta=\\{\\beta,\\Sigma\\}\\) from those observed data. This is a critical task from which one can gain understanding on the underlying process mechanics.\nOne classical parameter estimation approach is that of maximum likelihood. In some rare cases, when the SDE is such that the likelihood of the observations can be computed explicitly as a function of the parameters \\(\\theta\\), the estimation then resorts to a classical estimation task. However, in many cases this approach is not possible, and a classical procedure is to locally linearize the EDS. Many approaches have been proposed over the last decades, all with strengths and weaknesses (Pilipovic, Samson, and Ditlevsen 2024).\nTo the extent of our knowledge, another feature of SDEs has been under-used in the estimation context. Indeed, let \\(p(x,t;\\theta)\\) be the density function of \\(X_t\\) for a given set of parameters \\(\\theta\\). The behavior of \\(p(x,t;\\theta)\\) is described by the Fokker-Planck Equation (FPE) (Risken 1989), which is the Partial Differential Equation (PDE) defined by \\[\\begin{eqnarray*}\n    \\label{eq:fpe}\n    \\frac{\\partial p(x,t;\\theta)}{\\partial t}&=&-\\nabla\\cdot(F(x;\\beta)p(x,t;\\theta))+\\frac{1}{2}\\nabla\\cdot\\left(\\Sigma\\Sigma^\\top\\nabla p(x,t;\\theta)\\right),\\\\\n    p(\\cdot ,0;\\theta)&=&p_0\n\\end{eqnarray*}\\] where \\(\\nabla\\) and \\(\\nabla \\cdot\\) denotes the gradient and divergence operators. Thus, solving this PDE would provide an implicit expression of the marginal likelihood of each observation \\(x_{t_i}\\), which is a first step towards the maximum likelihood estimation of \\(\\theta\\).\nIn the past few years, the emergence of Physics-Informed Neural Networks (PINNs) (Raissi, Perdikaris, and Karniadakis 2019) has led to a fundamental rethinking of traditional approaches to solving partial differential equations. In a few words, the PINNs approach seeks to find the best neural network \\(u_\\nu\\) (\\(\\nu\\) being the set of weights and biases) representing the solution of the PDE in the form \\(\\mathcal{N}_\\theta[u]=0\\), where \\(\\mathcal{N}_\\theta\\) is an arbitrary differential operator, by minimizing its residuals computed at randomly sampled collocation points, in a so-called forward problem. This mesh-less approach has proven useful in a variety of contexts. It can also be extended to inverse problems where one seeks to learn the differential operator’s parameters \\(\\theta\\) given some observations of the solution \\(p(x_i,t_j;\\theta)\\), thus offering a flexible way to incorporate available “data” in the training.\nTwo additional difficulties arise in the context of this internship:\n\nFirst, \\(p(x,t;\\theta)\\) being a density function, the PINN is expected to learn a normalized probability density, hence one must ensure that, for any \\(t\\), \\(\\int_{\\Omega}p(x,t;\\theta )\\mathrm{d}x=1\\).\nSecond, we do not observe the solution itself but realisations of the SDE at discrete time points, whose marginal distribution is the solution of the PDE.\n\nA recent line of research uses PINNs for simulation or parameter estimation in SDEs via their FPE (Feng, Zeng, and Zhou 2021; Chen et al. 2020; Liu, Wu, and Zhang 2023), as we have just described. In this context, building on the previous articles, we explore the connection between SDEs, their FPE, and the Physics-Informed Neural Network (PINN) methodology.\n\n\nWe have an open position for a M2 student’s 6-month internship starting in 2026. The internship aims at proposing an efficient neural network architecture and optimisation scheme to accurately solve a FPE (forward problem) and perform parameter estimation (inverse problem) by using observational data that are assumed to be generated by the corresponding SDE. All the details are available here.\n\n\n\nChen, Xiaoli, Liu Yang, Jinqiao Duan, and George Em Karniadakis. 2020. “Solving Inverse Stochastic Problems from Discrete Particle Observations Using the Fokker-Planck Equation and Physics-Informed Neural Networks.” https://arxiv.org/abs/2008.10653.\n\n\nDegond, Pierre, Maxime Herda, and Sepideh Mirrahimi. 2020. “A Fokker-Planck approach to the study of robustness in gene expression.” Mathematical Biosciences and Engineering 17 (6): 6459–86. https://doi.org/10.3934/mbe.2020338.\n\n\nDitlevsen, Peter, and Susanne Ditlevsen. 2023. “Warning of a Forthcoming Collapse of the Atlantic Meridional Overturning Circulation.” Nature Communications 14 (1): 1–12.\n\n\nFeng, Xiaodong, Li Zeng, and Tao Zhou. 2021. “Solving Time Dependent Fokker-Planck Equations via Temporal Normalizing Flow.” arXiv Preprint arXiv:2112.14012.\n\n\nLiu, Feng, Faguo Wu, and Xiao Zhang. 2023. “PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning.” https://arxiv.org/abs/2309.15139.\n\n\nMichelot, Théo, Pierre Gloaguen, Paul G. Blackwell, and Marie-Pierre Etienne. 2019. “The Langevin Diffusion as a Continuous-Time Model of Animal Movement and Habitat Selection.” Methods in Ecology and Evolution 10 (11). https://doi.org/https://doi.org/10.1111/2041-210X.13275.\n\n\nØksendal, Bernt. 2003. “Stochastic Differential Equations.” In Stochastic Differential Equations: An Introduction with Applications, 38–50. Springer.\n\n\nPilipovic, Predrag, Adeline Samson, and Susanne Ditlevsen. 2024. “Parameter Estimation in Nonlinear Multivariate Stochastic Differential Equations Based on Splitting Schemes.” The Annals of Statistics 52 (2): 842–67.\n\n\nRaissi, Maziar, Paris Perdikaris, and George E Karniadakis. 2019. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707.\n\n\nRisken, Hannes. 1989. “Fokker-Planck Equation.” In The Fokker-Planck Equation: Methods of Solution and Applications, 63–95. Springer."
  },
  {
    "objectID": "posts/pinns_sde/index.html#physics-informed-neural-networks-for-sdes",
    "href": "posts/pinns_sde/index.html#physics-informed-neural-networks-for-sdes",
    "title": "Physics-Informed Neural Networks for parameter estimation in SDEs",
    "section": "",
    "text": "Stochastic Differential Equations (SDEs) are popular models in many fields including spatial ecology (Michelot et al. 2019), climate science (Ditlevsen and Ditlevsen 2023) and biology (Degond, Herda, and Mirrahimi 2020). Diffusion SDEs with additive noise are commonly found and defined as in Øksendal (2003): \\[\\mathrm{d}X_t=F(X_t;\\beta)\\, \\mathrm{d}t+\\Sigma\\, \\mathrm{d}W_t, \\quad X_0\\sim p_0\\] where \\((X_t)_t \\in\\mathbb{R}^d\\) is the stochastic process of interest, \\(W_t\\) is a \\(d\\)-dimensional Brownian noise, \\(p_0\\) is the initial distribution, \\(\\beta\\) parametrizes the drift of the equation and \\(\\Sigma\\) is the diffusion coefficient.\nWhen proposing such a model for observed trajectories at discrete times \\((x_{t_1}, \\dots, x_{t_n})\\), the next step consists in estimating the parameter \\(\\theta=\\{\\beta,\\Sigma\\}\\) from those observed data. This is a critical task from which one can gain understanding on the underlying process mechanics.\nOne classical parameter estimation approach is that of maximum likelihood. In some rare cases, when the SDE is such that the likelihood of the observations can be computed explicitly as a function of the parameters \\(\\theta\\), the estimation then resorts to a classical estimation task. However, in many cases this approach is not possible, and a classical procedure is to locally linearize the EDS. Many approaches have been proposed over the last decades, all with strengths and weaknesses (Pilipovic, Samson, and Ditlevsen 2024).\nTo the extent of our knowledge, another feature of SDEs has been under-used in the estimation context. Indeed, let \\(p(x,t;\\theta)\\) be the density function of \\(X_t\\) for a given set of parameters \\(\\theta\\). The behavior of \\(p(x,t;\\theta)\\) is described by the Fokker-Planck Equation (FPE) (Risken 1989), which is the Partial Differential Equation (PDE) defined by \\[\\begin{eqnarray*}\n    \\label{eq:fpe}\n    \\frac{\\partial p(x,t;\\theta)}{\\partial t}&=&-\\nabla\\cdot(F(x;\\beta)p(x,t;\\theta))+\\frac{1}{2}\\nabla\\cdot\\left(\\Sigma\\Sigma^\\top\\nabla p(x,t;\\theta)\\right),\\\\\n    p(\\cdot ,0;\\theta)&=&p_0\n\\end{eqnarray*}\\] where \\(\\nabla\\) and \\(\\nabla \\cdot\\) denotes the gradient and divergence operators. Thus, solving this PDE would provide an implicit expression of the marginal likelihood of each observation \\(x_{t_i}\\), which is a first step towards the maximum likelihood estimation of \\(\\theta\\).\nIn the past few years, the emergence of Physics-Informed Neural Networks (PINNs) (Raissi, Perdikaris, and Karniadakis 2019) has led to a fundamental rethinking of traditional approaches to solving partial differential equations. In a few words, the PINNs approach seeks to find the best neural network \\(u_\\nu\\) (\\(\\nu\\) being the set of weights and biases) representing the solution of the PDE in the form \\(\\mathcal{N}_\\theta[u]=0\\), where \\(\\mathcal{N}_\\theta\\) is an arbitrary differential operator, by minimizing its residuals computed at randomly sampled collocation points, in a so-called forward problem. This mesh-less approach has proven useful in a variety of contexts. It can also be extended to inverse problems where one seeks to learn the differential operator’s parameters \\(\\theta\\) given some observations of the solution \\(p(x_i,t_j;\\theta)\\), thus offering a flexible way to incorporate available “data” in the training.\nTwo additional difficulties arise in the context of this internship:\n\nFirst, \\(p(x,t;\\theta)\\) being a density function, the PINN is expected to learn a normalized probability density, hence one must ensure that, for any \\(t\\), \\(\\int_{\\Omega}p(x,t;\\theta )\\mathrm{d}x=1\\).\nSecond, we do not observe the solution itself but realisations of the SDE at discrete time points, whose marginal distribution is the solution of the PDE.\n\nA recent line of research uses PINNs for simulation or parameter estimation in SDEs via their FPE (Feng, Zeng, and Zhou 2021; Chen et al. 2020; Liu, Wu, and Zhang 2023), as we have just described. In this context, building on the previous articles, we explore the connection between SDEs, their FPE, and the Physics-Informed Neural Network (PINN) methodology.\n\n\nWe have an open position for a M2 student’s 6-month internship starting in 2026. The internship aims at proposing an efficient neural network architecture and optimisation scheme to accurately solve a FPE (forward problem) and perform parameter estimation (inverse problem) by using observational data that are assumed to be generated by the corresponding SDE. All the details are available here.\n\n\n\nChen, Xiaoli, Liu Yang, Jinqiao Duan, and George Em Karniadakis. 2020. “Solving Inverse Stochastic Problems from Discrete Particle Observations Using the Fokker-Planck Equation and Physics-Informed Neural Networks.” https://arxiv.org/abs/2008.10653.\n\n\nDegond, Pierre, Maxime Herda, and Sepideh Mirrahimi. 2020. “A Fokker-Planck approach to the study of robustness in gene expression.” Mathematical Biosciences and Engineering 17 (6): 6459–86. https://doi.org/10.3934/mbe.2020338.\n\n\nDitlevsen, Peter, and Susanne Ditlevsen. 2023. “Warning of a Forthcoming Collapse of the Atlantic Meridional Overturning Circulation.” Nature Communications 14 (1): 1–12.\n\n\nFeng, Xiaodong, Li Zeng, and Tao Zhou. 2021. “Solving Time Dependent Fokker-Planck Equations via Temporal Normalizing Flow.” arXiv Preprint arXiv:2112.14012.\n\n\nLiu, Feng, Faguo Wu, and Xiao Zhang. 2023. “PINF: Continuous Normalizing Flows for Physics-Constrained Deep Learning.” https://arxiv.org/abs/2309.15139.\n\n\nMichelot, Théo, Pierre Gloaguen, Paul G. Blackwell, and Marie-Pierre Etienne. 2019. “The Langevin Diffusion as a Continuous-Time Model of Animal Movement and Habitat Selection.” Methods in Ecology and Evolution 10 (11). https://doi.org/https://doi.org/10.1111/2041-210X.13275.\n\n\nØksendal, Bernt. 2003. “Stochastic Differential Equations.” In Stochastic Differential Equations: An Introduction with Applications, 38–50. Springer.\n\n\nPilipovic, Predrag, Adeline Samson, and Susanne Ditlevsen. 2024. “Parameter Estimation in Nonlinear Multivariate Stochastic Differential Equations Based on Splitting Schemes.” The Annals of Statistics 52 (2): 842–67.\n\n\nRaissi, Maziar, Paris Perdikaris, and George E Karniadakis. 2019. “Physics-Informed Neural Networks: A Deep Learning Framework for Solving Forward and Inverse Problems Involving Nonlinear Partial Differential Equations.” Journal of Computational Physics 378: 686–707.\n\n\nRisken, Hannes. 1989. “Fokker-Planck Equation.” In The Fokker-Planck Equation: Methods of Solution and Applications, 63–95. Springer."
  }
]